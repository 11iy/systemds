#-------------------------------------------------------------
#
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.
#
#-------------------------------------------------------------

#
# Builtin script implementing prediction based on classification trees with scale features using prediction methods of the
# Hummingbird paper (https://www.usenix.org/system/files/osdi20-nakandala.pdf).
#
# INPUT:
# ------------------------------------------------------------------------
# M           Decision tree matrix M, as generated by scripts/builtin/decisionTree.dml, where each column corresponds 
#             to a node in the learned tree and each row contains the following information:
#             M[1,j]: id of node j (in a complete binary tree)
#             M[2,j]: Offset (no. of columns) to left child of j if j is an internal node, otherwise 0
#             M[3,j]: Feature index of the feature (scale feature id if the feature is scale or
#             categorical feature id if the feature is categorical)
#             that node j looks at if j is an internal node, otherwise 0
#             M[4,j]: Type of the feature that node j looks at if j is an internal node: holds
#             the same information as R input vector
#             M[5,j]: If j is an internal node: 1 if the feature chosen for j is scale,
#             otherwise the size of the subset of values
#             stored in rows 6,7,... if j is categorical
#             If j is a leaf node: number of misclassified samples reaching at node j
#             M[6:,j]: If j is an internal node: Threshold the example's feature value is compared
#             to is stored at M[6,j] if the feature chosen for j is scale,
#             otherwise if the feature chosen for j is categorical rows 6,7,... depict the value subset chosen for j
#             If j is a leaf node 1 if j is impure and the number of samples at j > threshold, otherwise 0
# X           Feature matrix X
# strategy    Prediction strategy, can be one of ["GEMM", "TT", "PTT"], referring to "Generic matrix multiplication", 
#             "Tree traversal", and "Perfect tree traversal", respectively
# ----------------------------------------------------------------------
#
# OUTPUT:
# ------------------------------------------------------------------
# Y     Matrix containing the predicted labels for X 
# ------------------------------------------------------------------

m_decisionTreePredict = function(Matrix[Double] M, Matrix[Double] X, String strategy)
  return (Matrix[Double] Y) 
{
  if( strategy == "TT" )
    Y = predict_TT(M, X);
  else {
    print ("No such strategy" + strategy)
    Y = matrix("0", rows=0, cols=0)
  }
}

predict_TT = function (Matrix[Double] M, Matrix[Double] X) 
  return (Matrix[Double] Y)
{
  # initialization of model tensors and parameters
  [N_L, N_R, N_F, N_T] = createNodeTensors(M)
  nr = nrow(X); n = ncol(M);
  tree_depth = ceiling(log(n+1,2)) # max depth

  Ti = matrix(1, nr, 1); # current nodes (start at root)
  noChange = FALSE; i = 1;
  while( !noChange & i < tree_depth) {
    P = table(seq(1,nr), Ti, nr, n);
    TF = P %*% t(N_F); # get node feature indexes
    Tv = rowSums(X * table(seq(1,nr),TF,nr,ncol(X))); # get feature values
    Tt = P %*% t(N_T); # get node thresholds
    TL = P %*% t(N_L); # get node left paths
    TR = P %*% t(N_R); # get node right paths
    # pick left or right path for each record separately
    Ti_new = ifelse(Tv < Tt, TL, TR);
    noChange = (sum(Ti != Ti_new) == 0);
    i = i + 1;
    Ti = Ti_new;
  }

  # extract classes
  Y = t(table(seq(1,nr), Ti, nr, n) %*%  t(M[4,]));
}

createNodeTensors = function( Matrix[Double] M )
  return ( Matrix[Double] N_L, Matrix[Double] N_R, Matrix[Double] N_F, Matrix[Double] N_T)
{
  N = M[1,] # all tree nodes
  I = M[2,] # list of node offsets to their left children
  n_nodes  = ncol(N)

  # left/right child node ids, default self-id
  P1 = table(seq(1,ncol(N)), seq(1,ncol(I))+t(I[1,]));
  N_L = ifelse(I[1,]!=0, t(P1 %*% t(N)), t(seq(1, n_nodes)));
  P2 = table(seq(1,ncol(N)), t(N_L+1), ncol(N), ncol(N));
  N_R = ifelse(I[1,]!=0, t(P2 %*% t(N)), t(seq(1, n_nodes)));

  # node feature IDs (positions) and threshold values
  N_F = ifelse(M[3,]!=0, M[3,], 1);
  N_T = M[6,]; # threshold values for inner nodes, otherwise 0
}
