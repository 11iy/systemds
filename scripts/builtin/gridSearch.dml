#-------------------------------------------------------------
#
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.
#
#-------------------------------------------------------------

m_gridSearch = function(Matrix[Double] X, Matrix[Double] y, String train, String predict,
  List[String] params, List[Unknown] paramValues, Boolean verbose = TRUE) 
  return (Matrix[Double] B, Frame[Unknown] opt) 
{
  # Step 0) preparation of parameters, lengths, and values in convenient form
  numParams = length(params);
  paramLens = matrix(0, numParams, 1);
  for( j in 1:numParams ) {
    vect = as.matrix(paramValues[j,1]);
    paramLens[j,1] = nrow(vect);
  }
  paramVals = matrix(0, numParams, max(paramLens));
  for( j in 1:numParams ) {
    vect = as.matrix(paramValues[j,1]);
    paramVals[j,1:nrow(vect)] = t(vect);
  }
	cumLens = rev(cumprod(rev(paramLens))/rev(paramLens));
	numConfigs = prod(paramLens);
  
  # Step 1) materialize hyper-parameter combinations 
  # (simplify debugging and compared to compute negligible)
  HP = matrix(0, numConfigs, numParams);
  parfor( i in 1:nrow(HP) ) {
    for( j in 1:numParams )
      HP[i,j] = paramVals[j,as.scalar(((i-1)/cumLens[j,1])%%paramLens[j,1]+1)];
  }

  if( verbose )
    print("GridSeach: Hyper-parameter combinations: \n"+toString(HP));

  # Step 2) training/scoring of parameter combinations
  # TODO integrate cross validation
  Rbeta = matrix(0, nrow(HP), ncol(X));
  Rloss = matrix(0, nrow(HP), 1);
  arguments = list(X=X, y=y);

  parfor( i in 1:nrow(HP) ) {
    # a) prepare training arguments
    largs = arguments;
    for( j in 1:numParams ) {
      key = as.scalar(params[j]);
      value = as.scalar(HP[i,j]);
      largs = append(largs, list(key=value));
    }

    # b) core training/scoring
    lbeta = eval(train, largs);
    lloss = eval(predict, list(X, y, lbeta));

    # c) write models and loss back to output
    Rbeta[i,] = lbeta;
    Rloss[i,] = lloss;
  }

  # Step 3) select best parameter combination
  ix = as.scalar(rowIndexMin(t(Rloss)));
  B = Rbeta[ix,];          # optimal model
  opt = as.frame(HP[ix,]); # optimal hyper-parameters
}
